{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91cd2db7",
   "metadata": {},
   "source": [
    "##### To extract the content from the provided Harry potter pdf file.\n",
    "PyMuPDF (aka \"fitz\") is the Python bindings for MuPDF. using the start marker and end marker, we iterate through the pdf pages and check for the starting marker and if the starting marker is found, add the page text to text_to_extract variable and break the text extraction if the end_marker has found. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0264288",
   "metadata": {},
   "source": [
    "#### DATE OF BIRTH : 06/15/2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7161cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text between 'P a g e | 15\n",
      "Harry Potter and the Half Blood Prince – J.K. Rowling' and 'P a g e | 25\n",
      "www.ztcprep.com\n",
      "Harry Potter and the Half Blood Prince – J.K. Rowling' and saved to 'file1.txt'\n"
     ]
    }
   ],
   "source": [
    "import fitz \n",
    "\n",
    "def extract_text_between_markers(pdf_path, start_marker, end_marker, output_file_path):\n",
    "    try:\n",
    "        \n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Initialize an empty text variable to store extracted text\n",
    "        text_to_extract = \"\"\n",
    "\n",
    "        # To indicate the start marker has found\n",
    "        found_start = False\n",
    "\n",
    "        #Iterating through the text and extracting the required content\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_number)\n",
    "            page_text = page.get_text()\n",
    "\n",
    "            if start_marker in page_text:\n",
    "                found_start = True\n",
    "\n",
    "            if found_start:\n",
    "                text_to_extract += page_text\n",
    "\n",
    "            if end_marker in page_text:\n",
    "                break\n",
    "\n",
    "        #  Removing the content before start and end marker\n",
    "        start_index = text_to_extract.find(start_marker)\n",
    "        end_index = text_to_extract.find(end_marker)\n",
    "\n",
    "        if start_index != -1 and end_index != -1:\n",
    "            text_to_extract = text_to_extract[start_index + len(start_marker):end_index].strip()\n",
    "\n",
    "        # Saving to a txt file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(text_to_extract)\n",
    "\n",
    "        print(f\"Extracted text between '{start_marker}' and '{end_marker}' and saved to '{output_file_path}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        pdf_document.close()\n",
    "\n",
    "\n",
    "pdf_file_path = 'Harry_Potter_(www.ztcprep.com).pdf'\n",
    "start_marker = 'P a g e | 15\\nHarry Potter and the Half Blood Prince – J.K. Rowling'\n",
    "end_marker = 'P a g e | 25\\nwww.ztcprep.com\\nHarry Potter and the Half Blood Prince – J.K. Rowling'\n",
    "output_file_path = 'file1.txt'\n",
    "\n",
    "# Extract text between markers\n",
    "extract_text_between_markers(pdf_file_path, start_marker, end_marker, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc97f446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text between 'P a g e | 101\n",
      "Harry Potter and the Half Blood Prince – J.K. Rowling' and 'P a g e | 111\n",
      "Harry Potter and the Half Blood Prince – J.K. Rowling' and saved to 'file2.txt'\n"
     ]
    }
   ],
   "source": [
    "import fitz \n",
    "\n",
    "def extract_text_between_markers(pdf_path, start_marker, end_marker, output_file_path):\n",
    "    try:\n",
    "        # Create a PDF document object\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Initialize an empty text variable to store extracted text\n",
    "        text_to_extract = \"\"\n",
    "\n",
    "        # To indicate the start marker has found\n",
    "        found_start = False\n",
    "\n",
    "        # Iterate through the pages and extract the required content \n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_number)\n",
    "            page_text = page.get_text()\n",
    "\n",
    "            if start_marker in page_text:\n",
    "                found_start = True\n",
    "\n",
    "            if found_start:\n",
    "                text_to_extract += page_text\n",
    "\n",
    "            if end_marker in page_text:\n",
    "                break\n",
    "\n",
    "        # Removing the content before start and end marker\n",
    "        start_index = text_to_extract.find(start_marker)\n",
    "        end_index = text_to_extract.find(end_marker)\n",
    "\n",
    "        if start_index != -1 and end_index != -1:\n",
    "            text_to_extract = text_to_extract[start_index + len(start_marker):end_index].strip()\n",
    "\n",
    "        # Saving to a txt file\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(text_to_extract)\n",
    "\n",
    "        print(f\"Extracted text between '{start_marker}' and '{end_marker}' and saved to '{output_file_path}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        pdf_document.close()\n",
    "\n",
    "\n",
    "pdf_file_path = 'Harry_Potter_(www.ztcprep.com).pdf'\n",
    "start_marker = 'P a g e | 101\\nHarry Potter and the Half Blood Prince – J.K. Rowling'\n",
    "end_marker = 'P a g e | 111\\nHarry Potter and the Half Blood Prince – J.K. Rowling'\n",
    "output_file_path = 'file2.txt'\n",
    "\n",
    "# Extract text between markers\n",
    "extract_text_between_markers(pdf_file_path, start_marker, end_marker, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b001791",
   "metadata": {},
   "source": [
    "#### MAP_REDUCE using pyenchant \n",
    "Here we are using enchant and importing the dictionary to verify the words in our text file are legitimate english words.\n",
    "Then convert all words to lowercase and remove the punctuation marks and any other special characters from the text file so that it does'nt create any confusion while checking if words are valid english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4465eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyenchant in c:\\users\\ashri\\anaconda3\\lib\\site-packages (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyenchant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2aedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bones: 2\n",
      "head: 1\n",
      "of: 56\n",
      "the: 152\n",
      "department: 1\n",
      "magical: 2\n",
      "law: 2\n",
      "enforcement: 1\n",
      "we: 7\n",
      "think: 3\n",
      "he-who-must-not-be-: 1\n",
      "named: 3\n",
      "may: 1\n",
      "have: 3\n",
      "murdered: 1\n",
      "her: 22\n",
      "in: 33\n",
      "person: 2\n",
      "because: 2\n",
      "she: 15\n",
      "was: 27\n",
      "a: 84\n",
      "very: 7\n",
      "gifted: 1\n",
      "witch: 1\n",
      "and: 54\n",
      "all: 9\n",
      "evidence: 1\n",
      "that: 23\n",
      "put: 3\n",
      "up: 11\n",
      "real: 1\n",
      "fudge: 14\n",
      "cleared: 1\n",
      "his: 18\n",
      "throat: 1\n",
      "with: 18\n",
      "an: 9\n",
      "effort: 1\n",
      "it: 13\n",
      "seemed: 5\n",
      "stopped: 1\n",
      "spinning: 2\n",
      "bowler: 1\n",
      "hat: 1\n",
      "murder: 1\n",
      "said: 29\n",
      "prime: 30\n",
      "minister: 29\n",
      "momentarily: 3\n",
      "diverted: 1\n",
      "from: 13\n",
      "anger: 1\n",
      "newspapers: 1\n",
      "just: 7\n",
      "middle-aged: 1\n",
      "woman: 4\n",
      "who: 8\n",
      "lived: 1\n",
      "alone: 2\n",
      "nasty: 1\n",
      "killing: 1\n",
      "wasn’t: 4\n",
      "it’s: 3\n",
      "had: 15\n",
      "rather: 6\n",
      "lot: 1\n",
      "publicity: 1\n",
      "police: 1\n",
      "are: 2\n",
      "baffled: 1\n",
      "you: 20\n",
      "sighed: 1\n",
      "course: 2\n",
      "they: 7\n",
      "he: 21\n",
      "room: 3\n",
      "locked: 1\n",
      "inside: 1\n",
      "on: 9\n",
      "other: 6\n",
      "hand: 3\n",
      "know: 1\n",
      "exactly: 1\n",
      "did: 3\n",
      "not: 7\n",
      "gets: 3\n",
      "us: 1\n",
      "any: 2\n",
      "further: 1\n",
      "toward: 2\n",
      "catching: 3\n",
      "him: 11\n",
      "then: 5\n",
      "there: 7\n",
      "maybe: 3\n",
      "didn’t: 1\n",
      "hear: 2\n",
      "about: 3\n",
      "one: 3\n",
      "yes: 2\n",
      "i: 16\n",
      "happened: 1\n",
      "around: 6\n",
      "corner: 2\n",
      "here: 6\n",
      "as: 16\n",
      "matter: 1\n",
      "fact: 1\n",
      "papers: 1\n",
      "field: 1\n",
      "day: 2\n",
      "order: 1\n",
      "minister’s: 3\n",
      "backyard: 1\n",
      "if: 5\n",
      "barely: 3\n",
      "listening: 1\n",
      "to: 40\n",
      "got: 4\n",
      "swarming: 1\n",
      "over: 6\n",
      "place: 2\n",
      "attacking: 1\n",
      "people: 2\n",
      "left: 1\n",
      "right: 3\n",
      "center: 1\n",
      "once: 2\n",
      "upon: 3\n",
      "happier: 1\n",
      "time: 4\n",
      "this: 9\n",
      "sentence: 1\n",
      "would: 1\n",
      "been: 7\n",
      "unintelligible: 1\n",
      "but: 13\n",
      "wiser: 1\n",
      "now: 4\n",
      "thought: 6\n",
      "guard: 1\n",
      "prisoners: 1\n",
      "cautiously: 1\n",
      "p: 9\n",
      "g: 9\n",
      "e: 9\n",
      "16: 1\n",
      "harry: 9\n",
      "potter: 9\n",
      "half: 9\n",
      "blood: 9\n",
      "prince: 9\n",
      "wearily: 1\n",
      "anymore: 1\n",
      "they’ve: 1\n",
      "deserted: 2\n",
      "prison: 1\n",
      "joined: 1\n",
      "he-who-must-: 1\n",
      "not-be-named: 1\n",
      "won’t: 3\n",
      "pretend: 1\n",
      "sense: 1\n",
      "dawning: 1\n",
      "horror: 1\n",
      "tell: 1\n",
      "me: 4\n",
      "they’re: 2\n",
      "creatures: 2\n",
      "drain: 1\n",
      "hope: 1\n",
      "happiness: 1\n",
      "out: 6\n",
      "breeding: 1\n",
      "that’s: 4\n",
      "what’s: 1\n",
      "causing: 1\n",
      "sank: 1\n",
      "weak-kneed: 1\n",
      "into: 7\n",
      "nearest: 1\n",
      "chair: 1\n",
      "idea: 1\n",
      "invisible: 1\n",
      "swooping: 1\n",
      "through: 5\n",
      "towns: 1\n",
      "countryside: 1\n",
      "spreading: 1\n",
      "despair: 1\n",
      "hopelessness: 1\n",
      "voters: 1\n",
      "made: 2\n",
      "feel: 1\n",
      "quite: 1\n",
      "faint: 2\n",
      "see: 1\n",
      "you’ve: 1\n",
      "do: 6\n",
      "something: 1\n",
      "your: 7\n",
      "responsibility: 1\n",
      "dear: 1\n",
      "can’t: 3\n",
      "honestly: 1\n",
      "still: 4\n",
      "magic: 3\n",
      "after: 4\n",
      "sacked: 1\n",
      "three: 2\n",
      "days: 1\n",
      "ago: 1\n",
      "whole: 2\n",
      "community: 2\n",
      "has: 6\n",
      "screaming: 1\n",
      "for: 15\n",
      "my: 5\n",
      "resignation: 1\n",
      "fortnight: 2\n",
      "never: 1\n",
      "known: 1\n",
      "them: 6\n",
      "so: 8\n",
      "united: 1\n",
      "term: 1\n",
      "brave: 1\n",
      "attempt: 1\n",
      "at: 14\n",
      "smile: 4\n",
      "lost: 1\n",
      "words: 2\n",
      "despite: 1\n",
      "indignation: 1\n",
      "position: 1\n",
      "which: 4\n",
      "placed: 1\n",
      "felt: 1\n",
      "shrunken-: 1\n",
      "looking: 3\n",
      "man: 6\n",
      "sitting: 1\n",
      "opposite: 1\n",
      "finally: 1\n",
      "there’s: 2\n",
      "anything: 1\n",
      "can: 4\n",
      "kind: 2\n",
      "is: 6\n",
      "nothing: 2\n",
      "sent: 1\n",
      "tonight: 1\n",
      "bring: 1\n",
      "date: 1\n",
      "recent: 1\n",
      "events: 1\n",
      "introduce: 1\n",
      "17: 1\n",
      "successor: 1\n",
      "he’d: 2\n",
      "be: 11\n",
      "by: 4\n",
      "he’s: 3\n",
      "busy: 3\n",
      "moment: 3\n",
      "much: 1\n",
      "going: 1\n",
      "looked: 5\n",
      "portrait: 3\n",
      "ugly: 1\n",
      "little: 2\n",
      "wearing: 1\n",
      "long: 6\n",
      "curly: 1\n",
      "silver: 1\n",
      "wig: 1\n",
      "digging: 1\n",
      "ear: 1\n",
      "point: 1\n",
      "quill: 1\n",
      "fudge’s: 1\n",
      "eye: 1\n",
      "finishing: 1\n",
      "letter: 1\n",
      "wish: 1\n",
      "sounding: 1\n",
      "bitter: 1\n",
      "first: 5\n",
      "writing: 1\n",
      "twice: 2\n",
      "past: 1\n",
      "budge: 1\n",
      "prepared: 1\n",
      "persuade: 1\n",
      "boy: 1\n",
      "might: 1\n",
      "well: 5\n",
      "will: 2\n",
      "more: 1\n",
      "subsided: 1\n",
      "what: 2\n",
      "clearly: 2\n",
      "aggrieved: 1\n",
      "silence: 1\n",
      "broken: 2\n",
      "almost: 3\n",
      "immediately: 2\n",
      "suddenly: 1\n",
      "spoke: 1\n",
      "its: 5\n",
      "crisp: 1\n",
      "official: 1\n",
      "voice: 4\n",
      "muggles: 2\n",
      "requesting: 1\n",
      "meeting: 1\n",
      "urgent: 1\n",
      "kindly: 2\n",
      "respond: 1\n",
      "distractedly: 1\n",
      "flinched: 1\n",
      "flames: 1\n",
      "grate: 1\n",
      "turned: 5\n",
      "emerald: 1\n",
      "green: 4\n",
      "again: 2\n",
      "rose: 1\n",
      "revealed: 1\n",
      "second: 5\n",
      "wizard: 1\n",
      "their: 3\n",
      "heart: 1\n",
      "disgorging: 1\n",
      "moments: 2\n",
      "later: 1\n",
      "onto: 1\n",
      "antique: 1\n",
      "rug: 1\n",
      "feet: 1\n",
      "moment’s: 1\n",
      "hesitation: 1\n",
      "same: 1\n",
      "watching: 1\n",
      "new: 3\n",
      "arrival: 1\n",
      "straighten: 1\n",
      "dust: 1\n",
      "down: 6\n",
      "black: 4\n",
      "robes: 2\n",
      "look: 3\n",
      "foolish: 1\n",
      "like: 3\n",
      "old: 3\n",
      "lion: 1\n",
      "18: 1\n",
      "were: 6\n",
      "streaks: 1\n",
      "gray: 1\n",
      "mane: 1\n",
      "tawny: 1\n",
      "hair: 3\n",
      "bushy: 1\n",
      "keen: 1\n",
      "yellowish: 1\n",
      "eyes: 5\n",
      "behind: 3\n",
      "pair: 2\n",
      "wire-rimmed: 1\n",
      "spectacles: 1\n",
      "certain: 1\n",
      "rangy: 1\n",
      "loping: 1\n",
      "grace: 1\n",
      "even: 1\n",
      "though: 3\n",
      "walked: 1\n",
      "slight: 1\n",
      "limp: 1\n",
      "immediate: 1\n",
      "impression: 1\n",
      "shrewdness: 1\n",
      "understood: 1\n",
      "why: 1\n",
      "preferred: 1\n",
      "leader: 1\n",
      "these: 1\n",
      "dangerous: 1\n",
      "times: 1\n",
      "politely: 1\n",
      "holding: 2\n",
      "grasped: 1\n",
      "briefly: 1\n",
      "scanning: 1\n",
      "pulled: 1\n",
      "wand: 5\n",
      "under: 5\n",
      "told: 2\n",
      "asked: 3\n",
      "striding: 1\n",
      "door: 5\n",
      "tapping: 1\n",
      "keyhole: 1\n",
      "heard: 2\n",
      "lock: 1\n",
      "click: 1\n",
      "don’t: 1\n",
      "mind: 1\n",
      "remained: 1\n",
      "shortly: 1\n",
      "added: 1\n",
      "pointing: 1\n",
      "windows: 4\n",
      "curtains: 3\n",
      "swept: 1\n",
      "across: 3\n",
      "let’s: 1\n",
      "get: 1\n",
      "business: 1\n",
      "need: 1\n",
      "discuss: 1\n",
      "drew: 2\n",
      "himself: 1\n",
      "fullest: 1\n",
      "height: 1\n",
      "replied: 1\n",
      "am: 2\n",
      "perfectly: 1\n",
      "happy: 2\n",
      "security: 1\n",
      "already: 6\n",
      "thank: 1\n",
      "we’re: 1\n",
      "cut: 1\n",
      "poor: 1\n",
      "lookout: 1\n",
      "curse: 1\n",
      "secretary: 1\n",
      "outer: 1\n",
      "office: 2\n",
      "19: 1\n",
      "getting: 1\n",
      "rid: 1\n",
      "you’re: 2\n",
      "hotly: 1\n",
      "highly: 2\n",
      "efficient: 1\n",
      "work: 2\n",
      "rest: 2\n",
      "without: 1\n",
      "flicker: 1\n",
      "trained: 1\n",
      "assigned: 1\n",
      "wait: 1\n",
      "declared: 1\n",
      "decide: 1\n",
      "works: 1\n",
      "coldly: 1\n",
      "say: 2\n",
      "no: 3\n",
      "problem: 1\n",
      "continues: 1\n",
      "er: 1\n",
      "lamely: 1\n",
      "junior: 1\n",
      "continued: 1\n",
      "entertaining: 1\n",
      "public: 1\n",
      "impersonating: 1\n",
      "reacted: 1\n",
      "poorly: 1\n",
      "performed: 1\n",
      "addled: 1\n",
      "brains: 1\n",
      "could: 2\n",
      "only: 1\n",
      "weakly: 1\n",
      "bit: 1\n",
      "go: 3\n",
      "easy: 1\n",
      "drink: 1\n",
      "20: 1\n",
      "team: 1\n",
      "healers: 1\n",
      "st: 1\n",
      "hospital: 1\n",
      "maladies: 1\n",
      "injuries: 1\n",
      "examining: 1\n",
      "speak: 3\n",
      "far: 1\n",
      "attempted: 2\n",
      "strangle: 1\n",
      "best: 1\n",
      "remove: 1\n",
      "muggle: 2\n",
      "society: 1\n",
      "he’ll: 1\n",
      "anxiously: 1\n",
      "merely: 3\n",
      "shrugged: 1\n",
      "moving: 1\n",
      "back: 6\n",
      "fireplace: 1\n",
      "really: 2\n",
      "keep: 1\n",
      "posted: 1\n",
      "developments: 1\n",
      "or: 1\n",
      "least: 1\n",
      "shall: 2\n",
      "probably: 1\n",
      "too: 3\n",
      "come: 1\n",
      "personally: 1\n",
      "case: 2\n",
      "send: 1\n",
      "consented: 1\n",
      "stay: 1\n",
      "advisory: 1\n",
      "toothache: 1\n",
      "rummaging: 1\n",
      "pocket: 1\n",
      "mysterious: 1\n",
      "powder: 1\n",
      "fire: 2\n",
      "gazed: 1\n",
      "hopelessly: 1\n",
      "fought: 1\n",
      "suppress: 1\n",
      "evening: 1\n",
      "burst: 1\n",
      "last: 3\n",
      "heaven’s: 1\n",
      "sake: 1\n",
      "wizards: 2\n",
      "surely: 1\n",
      "sort: 1\n",
      "slowly: 1\n",
      "spot: 1\n",
      "exchanged: 1\n",
      "incredulous: 1\n",
      "manage: 1\n",
      "trouble: 1\n",
      "side: 3\n",
      "two: 2\n",
      "stepped: 1\n",
      "bright: 1\n",
      "vanished: 1\n",
      "21: 1\n",
      "spinner’s: 2\n",
      "end: 2\n",
      "many: 1\n",
      "miles: 1\n",
      "away: 2\n",
      "chilly: 1\n",
      "mist: 1\n",
      "pressed: 1\n",
      "against: 1\n",
      "drifted: 1\n",
      "dirty: 2\n",
      "river: 4\n",
      "wound: 1\n",
      "between: 3\n",
      "overgrown: 1\n",
      "rubbish-: 1\n",
      "strewn: 1\n",
      "banks: 1\n",
      "immense: 1\n",
      "chimney: 2\n",
      "relic: 1\n",
      "disused: 1\n",
      "mill: 2\n",
      "reared: 1\n",
      "shadowy: 1\n",
      "ominous: 1\n",
      "sound: 1\n",
      "apart: 2\n",
      "whisper: 2\n",
      "water: 1\n",
      "sign: 1\n",
      "life: 1\n",
      "scrawny: 1\n",
      "fox: 5\n",
      "slunk: 1\n",
      "bank: 4\n",
      "nose: 1\n",
      "hopefully: 1\n",
      "some: 2\n",
      "fish-and-chip: 1\n",
      "wrappings: 1\n",
      "tall: 1\n",
      "grass: 2\n",
      "pop: 2\n",
      "slim: 1\n",
      "hooded: 2\n",
      "figure: 4\n",
      "appeared: 1\n",
      "thin: 1\n",
      "air: 1\n",
      "edge: 1\n",
      "froze: 1\n",
      "wary: 1\n",
      "fixed: 1\n",
      "strange: 1\n",
      "phenomenon: 1\n",
      "take: 1\n",
      "bearings: 1\n",
      "few: 2\n",
      "set: 2\n",
      "off: 1\n",
      "light: 7\n",
      "quick: 1\n",
      "strides: 1\n",
      "cloak: 3\n",
      "rustling: 1\n",
      "louder: 1\n",
      "another: 3\n",
      "materialized: 1\n",
      "22: 1\n",
      "harsh: 1\n",
      "cry: 1\n",
      "startled: 1\n",
      "crouching: 1\n",
      "flat: 1\n",
      "undergrowth: 1\n",
      "leapt: 1\n",
      "hiding: 1\n",
      "flash: 3\n",
      "yelp: 1\n",
      "fell: 2\n",
      "ground: 1\n",
      "dead: 1\n",
      "animal: 1\n",
      "toe: 1\n",
      "woman’s: 1\n",
      "dismissively: 1\n",
      "hood: 3\n",
      "perhaps: 1\n",
      "quarry: 1\n",
      "paused: 1\n",
      "scrambling: 1\n",
      "fallen: 1\n",
      "listen: 2\n",
      "caught: 3\n",
      "seized: 1\n",
      "arm: 3\n",
      "wrenched: 1\n",
      "must: 3\n",
      "listened: 1\n",
      "decision: 1\n",
      "leave: 1\n",
      "gained: 1\n",
      "top: 1\n",
      "where: 2\n",
      "line: 1\n",
      "railings: 2\n",
      "separated: 1\n",
      "narrow: 1\n",
      "cobbled: 1\n",
      "street: 3\n",
      "followed: 3\n",
      "stood: 2\n",
      "road: 2\n",
      "rows: 2\n",
      "dilapidated: 1\n",
      "brick: 2\n",
      "houses: 3\n",
      "dull: 1\n",
      "blind: 1\n",
      "darkness: 2\n",
      "lives: 1\n",
      "contempt: 1\n",
      "dunghill: 1\n",
      "our: 1\n",
      "ever: 1\n",
      "foot: 1\n",
      "23: 1\n",
      "slipped: 1\n",
      "gap: 1\n",
      "rusty: 1\n",
      "hurrying: 1\n",
      "streaming: 2\n",
      "saw: 1\n",
      "darting: 1\n",
      "alley: 1\n",
      "identical: 1\n",
      "streetlamps: 1\n",
      "women: 1\n",
      "running: 1\n",
      "patches: 1\n",
      "deep: 1\n",
      "pursuer: 2\n",
      "prey: 1\n",
      "succeeding: 1\n",
      "hold: 1\n",
      "swinging: 1\n",
      "faced: 1\n",
      "each: 1\n",
      "trust: 1\n",
      "dark: 3\n",
      "lord: 2\n",
      "trusts: 1\n",
      "doesn’t: 1\n",
      "believe: 1\n",
      "panted: 1\n",
      "gleamed: 1\n",
      "check: 1\n",
      "indeed: 1\n",
      "plan: 1\n",
      "anyone: 1\n",
      "betrayal: 1\n",
      "lord’s: 1\n",
      "snarled: 1\n",
      "beneath: 1\n",
      "threateningly: 1\n",
      "other’s: 1\n",
      "face: 2\n",
      "laughed: 1\n",
      "own: 1\n",
      "sister: 2\n",
      "wouldn’t: 2\n",
      "breathed: 1\n",
      "note: 1\n",
      "hysteria: 1\n",
      "brought: 1\n",
      "knife: 1\n",
      "let: 1\n",
      "sister’s: 1\n",
      "burned: 1\n",
      "24: 1\n",
      "rushed: 1\n",
      "ahead: 1\n",
      "rubbing: 1\n",
      "keeping: 1\n",
      "distance: 1\n",
      "moved: 1\n",
      "deeper: 1\n",
      "labyrinth: 1\n",
      "hurried: 1\n",
      "towering: 1\n",
      "hover: 1\n",
      "giant: 1\n",
      "admonitory: 1\n",
      "finger: 1\n",
      "footsteps: 1\n",
      "echoed: 1\n",
      "cobbles: 1\n",
      "passed: 1\n",
      "boarded: 1\n",
      "until: 1\n",
      "reached: 1\n",
      "house: 1\n",
      "dim: 1\n",
      "glimmered: 1\n",
      "downstairs: 1\n",
      "knocked: 1\n",
      "before: 1\n",
      "cursing: 1\n",
      "breath: 1\n",
      "together: 1\n",
      "waiting: 1\n",
      "panting: 1\n",
      "slightly: 1\n",
      "breathing: 1\n",
      "smell: 1\n",
      "carried: 1\n",
      "night: 1\n",
      "breeze: 1\n",
      "seconds: 1\n",
      "movement: 1\n",
      "opened: 1\n",
      "crack: 1\n",
      "sliver: 1\n",
      "seen: 1\n",
      "parted: 1\n",
      "sallow: 1\n",
      "threw: 1\n",
      "pale: 1\n",
      "shine: 1\n",
      "blonde: 1\n",
      "gave: 1\n",
      "drowned: 1\n",
      "opening: 1\n",
      "wider: 1\n",
      "pleasant: 1\n",
      "strained: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import enchant\n",
    "\n",
    "# Initialize the English dictionary\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "# Read the txt file\n",
    "with open('file1.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Splitting the text into words\n",
    "words = text.split()\n",
    "\n",
    "# Counting the occurrences of each word\n",
    "word_counts = {}\n",
    "for word in words:\n",
    "    word = word.strip(\".,!?()[]{}\\\"'\")  # Remove punctuation\n",
    "    word = word.lower()  # Convert to lowercase\n",
    "    if word and d.check(word):  # Check if it's a valid English word\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "\n",
    "# Printing the word count\n",
    "for word, count in word_counts.items():\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5c7e9",
   "metadata": {},
   "source": [
    "### MAP_REDUCE to find NON-ENGLISH WORDS\n",
    "Similar to the previous step, we're going to import US dictionary and cross-check all the words in our txt file to map out all the non-english words and count them accordingly.\n",
    "\n",
    "Here we created a function to check if the word are valid english words. we then split the text file into wordsand call the function to check. Then we initialize a dictionary named non_english_word_counts to count the no.of occurences of that non-english word. \n",
    "\n",
    "We iterated through each word that we splitted from txt file and passed it through the fucntion to check and count those words that are non-english and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a503cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ron: 28\n",
      "www: 16\n",
      "ztcprep: 16\n",
      "hermione: 28\n",
      "arry: 4\n",
      "eet: 2\n",
      "mrs: 10\n",
      "weasley: 11\n",
      "fleur: 8\n",
      "delacour: 1\n",
      "im: 1\n",
      "seester: 1\n",
      "gabrielle: 1\n",
      "rowling: 9\n",
      "hadn: 2\n",
      "ze: 1\n",
      "ard: 1\n",
      "gringotts: 1\n",
      "eenglish: 1\n",
      "zere: 1\n",
      "isn: 3\n",
      "tchah: 1\n",
      "ve: 5\n",
      "tonks: 6\n",
      "auror: 1\n",
      "triwizard: 1\n",
      "hasn: 2\n",
      "sirius: 4\n",
      "azkaban: 1\n",
      "bellatrix: 2\n",
      "lestrange: 1\n",
      "wasn: 2\n",
      "couldn: 1\n",
      "lupin: 1\n",
      "didn: 3\n",
      "doesn: 1\n",
      "fred: 3\n",
      "george: 3\n",
      "diagon: 1\n",
      "percy: 1\n",
      "voldemort: 3\n",
      "dumbledore: 7\n",
      "lucius: 1\n",
      "malfoy: 1\n",
      "weren: 1\n",
      "wouldn: 2\n",
      "countercurses: 1\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "import re\n",
    "\n",
    "# Initializing the English dictionary\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "# Function to check if the word is non-English\n",
    "def is_non_english(word):\n",
    "    return not d.check(word)\n",
    "\n",
    "# Reading the txt file \n",
    "with open('file2.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# splitting the text into words\n",
    "words = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "# Count non-English words and their occurrences\n",
    "non_english_word_counts = {}\n",
    "for word in words:\n",
    "    word = word.lower()  # Converting to lowercase\n",
    "    if is_non_english(word):\n",
    "        if word in non_english_word_counts:\n",
    "            non_english_word_counts[word] += 1\n",
    "        else:\n",
    "            non_english_word_counts[word] = 1\n",
    "\n",
    "# Printing the non-English word count\n",
    "for word, count in non_english_word_counts.items():\n",
    "    print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82732ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
